
```{r}
challenger = read.csv("/Users/petergrabowski/w271/challenger.csv", header=TRUE)
```

# Introduction

## Questions addressed

## Methodology

## Highlight of Results

# EDA

# Discussion
# https://stats.stackexchange.com/questions/116954/counterexample-against-binomial-assumptions
#  also on page 4 of text
# 1 - fixed number of trials
# 2 - ** each observation is independent
# 3 - two and only two outcomes
# 4 - ** prob of success is the same for each trial
# 5 - random variable of interest w is the number of successes

# TODO 
# -- do we need to sum the number of failures for each trial and build a model based on that? The placekicking example on p75 takes a similar approach to ours, but in other examples they sum the number of success/failures

There were 23 rows representing each flight of the shuttle program. Included were the following columns:

|----------|---------|---------------------------------------------------------------------------------|
| Flight   | integer | flight number, serves as an ID for this dataset                                 |
| Temp     | int     | sea level temperature (## check this ##) at time of flight                      |
| Pressure | int     | there were three different levels of pressure for which the O-Rings were set to |
| O. Ring  | int     | the number of O-rings that failed in the launch                                 |
| Number   | int     | the number of O-rings that were installed in the aircraft                       |
|----------|---------|---------------------------------------------------------------------------------|

For the sake of the analysis, the following changes were made to the dataset:
1 - the column `ratio` was calculated to denote the proportion of failed O-Rings per flight
    ```{r}
    challenger$ratio = challenger$O.ring / challenger$Number
    plot(x=challenger$ratio, y=challenger$Temp)
    ```
2 - the column `had_failure` was calculated to denote the incidence of a failed O-Ring in the flight

####### Q4 ##########
####### 4A ##########
The necessity of this assumption stems from the requisitite assumptions when using a binomial regression model. The use of the model requires that all observations be independent of one another and have the same probability of failure. If not for this assumptionm, the regression model would be much more complicated. For a space shuttle, this might not be the case. For example, failure of one O-ring may cause stress throughout the rest of the system, influencing the likelihood that adjacent O-rings would fail. 

```{r}
challenger$Pressure = factor(challenger$Pressure)
```
```{r}
plot(x=challenger$ratio, y=challenger$Pressure)
```
```{r}
challenger
```

####### 4B ##########
```{r}
challenger$incidence = ifelse(challenger$O.ring > 0, 1, 0)
mod.fit = glm(formula = ratio ~ Temp + Pressure, family=binomial(link=logit), data=challenger)
mod.fit.incidence = glm(formula = incidence ~ Temp + Pressure, family=binomial(link=logit), data=challenger)
# Warning message:
# In eval(family$initialize) : non-integer #successes in a binomial glm!

mod.fit
```
```{r}
summary(mod.fit)
```

```{r}
mod.fit.incidence
```
```{r}
summary(mod.fit.incidence)
```

####### 4C ##########
```{r}
library(package = car)
Anova(mod.fit, test = "LR")
```
```{r}
Anova(mod.fit.incidence, test = "LR")
```
```{r}
anova(mod.fit, test = "Chisq")
```
```{r}
anova(mod.fit.incidence, test = "Chisq")
```

####### 4D ##########
The effect of pressure was not significant in any of the analyses we ran, which supports the authors' decision to remove it from the model. However, there are concerns that remain while removing it. As our graphic analysis above shows (TODO: insert Arunima analysis), there does seem to be some weak correlation with pressure. The sample size is very small, so it's possible this is masking an otherwise weak effect size. We also haven't checked for any interaction effects with pressure, which could influence the model. Finally, a model based on temperature alone relies on heavy extrapolation -- the predicted temperature of 31 degrees is well outside the range of the sample -- while including pressure also includes data from an overlapping range with teh sample. 

####### Q5 ##########
####### 5A ##########
```{r}
mod.fit2 = glm(formula = ratio ~ Temp , family=binomial(link=logit), data=challenger)
summary(mod.fit2)
```

```{r}
mod.fit2.incidence = glm(formula = incidence ~ Temp , family=binomial(link=logit), data=challenger)
summary(mod.fit2.incidence)
```

####### 5B ##########
```{r}
b0 = mod.fit2.incidence$coefficients[["(Intercept)"]]
b1 = mod.fit2.incidence$coefficients[["Temp"]]

eq2 = function(x){exp(b0 + b1*x) / (1+ exp( b0 + b1*x))}
curve(eq2, from=31, to=81, col='red')

b0 = mod.fit2$coefficients[["(Intercept)"]]
b1 = mod.fit2$coefficients[["Temp"]]

eq1 = function(x){exp(b0 + b1*x) / (1+ exp( b0 + b1*x))}
curve(eq1, from=31, to=81, col='blue', add=TRUE)
```

# TODO -- plot expected number of failures

####### 5C ##########
# page 89
```{r}
predict.data = data.frame(Temp = seq(from = 31, to = 81))
# linear.pred = predict(object = mod.fit2, newdata = predict.data, type = "link" , se = TRUE)
# linear.pred

alpha = 0.05
ci.pi = function(newdata, mod.fit.obj, alpha) {
  linear.pred = predict(object = mod.fit.obj, newdata = newdata, type = "link", se= TRUE)
  CI.lin.pred.lower = linear.pred$fit - qnorm(p = 1-alpha/2) * linear.pred$se
  CI.lin.pred.upper = linear.pred$fit + qnorm(p = 1-alpha/2) * linear.pred$se
  CI.pi.lower = exp(CI.lin.pred.lower) / (1+ exp(CI.lin.pred.lower))
  CI.pi.upper = exp(CI.lin.pred.upper) / (1+ exp(CI.lin.pred.upper))
  list(lower = CI.pi.lower, upper = CI.pi.upper)
}
```

The bounds are much wider at the lower range of the interval than the upper range because we have many fewere data points in this range. In the extreme lower range (near 31), we don't have any data points from our sample, so the confidence intervals are much larger.

```{r}
curve(expr=ci.pi(newdata = data.frame(Temp = x), mod.fit.obj = mod.fit2, alpha=0.05)$upper, lty = "dotdash", xlim=c(31,81))
curve(expr=ci.pi(newdata = data.frame(Temp = x), mod.fit.obj = mod.fit2, alpha=0.05)$lower, lty = "dotdash", add = TRUE, xlim=c(31,81))

# pi.hat = exp(linear.pred$fit) / (1 + exp(linear.pred$fit))
# CI.lin.pred = linear.pred$fit + qnorm(p = c(alpha/2, 1-alpha/2)) * linear.pred$se.fit
# CI.pi = exp(CI.lin.pred) / (1 + exp(CI.lin.pred))
```

```{r}
curve(expr=ci.pi(newdata = data.frame(Temp = x), mod.fit.obj = mod.fit2.incidence, alpha=0.05)$upper, lty = "dotdash", xlim=c(31,81))
curve(expr=ci.pi(newdata = data.frame(Temp = x), mod.fit.obj = mod.fit2.incidence, alpha=0.05)$lower, lty = "dotdash", add = TRUE, xlim=c(31,81))
# pi.hat = exp(linear.pred$fit) / (1 + exp(linear.pred$fit))
# CI.lin.pred = linear.pred$fit + qnorm(p = c(alpha/2, 1-alpha/2)) * linear.pred$se.fit
# CI.pi = exp(CI.lin.pred) / (1 + exp(CI.lin.pred))
```



```{r}
####### 5D ##########
temp_to_pred = data.frame(Temp=31)
temp_pred = predict(object = mod.fit2.incidence, newdata = temp_to_pred, type = "link", se= TRUE)
CI.lin.pred.lower = temp_pred$fit - qnorm(p = 1-alpha/2) * temp_pred$se
CI.lin.pred.upper = temp_pred$fit + qnorm(p = 1-alpha/2) * temp_pred$se
CI.pi.lower = exp(CI.lin.pred.lower) / (1+ exp(CI.lin.pred.lower))
CI.pi.upper = exp(CI.lin.pred.upper) / (1+ exp(CI.lin.pred.upper))

temp_pred
CI.pi.lower
CI.pi.upper
```
#TODO does this sound right, or are there different assumptions for inference??
We need to satisfy the five conditions for using a binomial model. First, there need to be a fixed number of identical trials. In our case, we're assuming that each shuttle launch was identical. Second, there need to be two possible outcomes for each option. In our case, we consider failure or non-failure of an O-ring. Third, each trial needs to be independent of one another. We make this assumptoin based on findings from the paper. Fourth, the probability of success needs to remain constant for each trial. With the information we have, there is no reason to believe success would be more or less likely from one trial to the next. Finally, the random variable needs to be the number of successes. In our case, we look at how many O-rings fail, not which O-rings are failing

```{r}
####### 5E ##########
####### parametric bootstrap ##########
```


```{r}
####### 5F ##########
####### quadratic term ##########
```

```{r}
####### LAB1 ##########
####### odds/prob failure ##########
# page 955 of text, compare 31 degrees to 60 degrees
```

```{r}
####### LAB2 ##########
####### linear regression ##########
# linear model
# http://r-statistics.co/Linear-Regression.html
# assessing model diagnostics
# https://www.statmethods.net/stats/rdiagnostics.html
```
